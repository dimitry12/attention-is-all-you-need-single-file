{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiattention(nn.Module):\n",
    "    def __init__(self, qk_channels, v_channels, multi_x8 = 1, # number of \"heads\"\n",
    "                                             keys_queries_projection_dim_x8 = 1,\n",
    "                                             values_projection_dim_x8 = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.q_projector = nn.Conv1d(qk_channels,keys_queries_projection_dim_x8*8*multi_x8*8, (1,), bias=False)\n",
    "        self.k_projector = nn.Conv1d(qk_channels,keys_queries_projection_dim_x8*8*multi_x8*8, (1,), bias=False)\n",
    "        self.v_projector = nn.Conv1d(v_channels,values_projection_dim_x8*8*multi_x8*8, (1,), bias=False)\n",
    "        \n",
    "        self.v_reprojector = nn.Conv1d(values_projection_dim_x8*8*multi_x8*8, v_channels, (1,), bias=False)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "        \n",
    "        self.multi_x8 = multi_x8\n",
    "        self.keys_queries_projection_dim_x8 = keys_queries_projection_dim_x8\n",
    "            \n",
    "    def forward(self, Q_source, K_source, V_source):\n",
    "        batch_size = V_source.size()[0]\n",
    "        dict_length = V_source.size()[1]\n",
    "        input_channels = V_source.size()[-1]\n",
    "        \n",
    "        #keys_projection_coeffs = Variable(torch.ones(1,1,K_source.size()[-1],keys_queries_projection_dim_x8*8*multi_x8*8))\n",
    "        #queries_projection_coeffs = Variable(torch.ones(1,1,Q_source.size()[-1],keys_queries_projection_dim_x8*8*multi_x8*8))\n",
    "        #values_projection_coeffs = Variable(torch.ones(1,1,input_channels,values_projection_dim_x8*8*multi_x8*8))\n",
    "        \n",
    "        def _project(tensor_to_project, projector):\n",
    "            _ = tensor_to_project\n",
    "            _ = _.permute(0,2,1)\n",
    "            _ = projector(_)\n",
    "            _ = _.permute(0,2,1)\n",
    "            _ = _.contiguous()\n",
    "            _ = _.view(tensor_to_project.size()[0],tensor_to_project.size()[1],self.multi_x8*8,-1)\n",
    "            _ = _.permute(0,2,1,3)\n",
    "            return _\n",
    "            \n",
    "        keys_projections = _project(K_source, self.k_projector) # [batch,heads,sequence,channels]\n",
    "        queries_projections = _project(Q_source, self.q_projector) # [batch,heads,sequence,channels]\n",
    "        values_projections = _project(V_source, self.v_projector) # [batch,heads,sequence,channels]\n",
    "        \n",
    "        _ = keys_projections.permute(0,1,3,2) # [batch,heads,channels,sequence]\n",
    "        _ = queries_projections.matmul(_) # [batch,heads,sequence,sequence]\n",
    "        _ = torch.div(_, math.sqrt(self.keys_queries_projection_dim_x8*8))\n",
    "        attention_softmaxed = self.softmax(_) # [batch,heads,sequence,sequence]\n",
    "        \n",
    "        # [batch,heads,sequence,channels]\n",
    "        projected_multiselfattended_input = attention_softmaxed.matmul(values_projections)\n",
    "        \n",
    "        _ = projected_multiselfattended_input\n",
    "        _ = _.permute(0,2,1,3)\n",
    "        _ = _.contiguous()\n",
    "        _ = _.view(_.size()[0], _.size()[1],-1) # [batch,sequence,channels]\n",
    "        _ = _.permute(0,2,1)\n",
    "        _ = self.v_reprojector(_)\n",
    "        _ = _.permute(0,2,1)\n",
    "        reprojected_multiselfattended_input = _\n",
    "        \n",
    "        return reprojected_multiselfattended_input\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_channels, ff_projection_dim_x8=None):\n",
    "        super().__init__()\n",
    "                     \n",
    "        if ff_projection_dim_x8 is None:\n",
    "            ff_projection_dim_x8 = input_channels // 8 # default to same number of channels as input\n",
    "            \n",
    "        self.projector = nn.Conv1d(input_channels, ff_projection_dim_x8*8, (1,), bias=True)\n",
    "        self.reprojector = nn.Conv1d(ff_projection_dim_x8*8, input_channels, (1,), bias=False)\n",
    "            \n",
    "    def forward(self, input_tensor):\n",
    "        _ = input_tensor\n",
    "        _ = _.permute(0,2,1)\n",
    "        _ = self.projector(_)\n",
    "        _ = _.permute(0,2,1)\n",
    "        _ = nn.functional.relu(_)\n",
    "        _ = _.permute(0,2,1)\n",
    "        _ = self.reprojector(_)\n",
    "        _ = _.permute(0,2,1)\n",
    "        \n",
    "        return _     \n",
    "        \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 ff_projection_dim_x8=None,\n",
    "                 multi_x8=1,\n",
    "                 keys_queries_projection_dim_x8=1,\n",
    "                 values_projection_dim_x8=1):\n",
    "        super().__init__()\n",
    "        self.ff = FeedForward(input_channels = input_channels,\n",
    "                              ff_projection_dim_x8 = ff_projection_dim_x8)\n",
    "        \n",
    "                        \n",
    "        self.multiattention_head_with_projections = Multiattention(qk_channels=input_channels,\n",
    "                                                                   v_channels=input_channels,\n",
    "                                                                   multi_x8=multi_x8,\n",
    "                                                                   keys_queries_projection_dim_x8=keys_queries_projection_dim_x8,\n",
    "                                                                   values_projection_dim_x8=values_projection_dim_x8)\n",
    "        \n",
    "        \n",
    "        self.attention_layer_norm = LayerNorm(features=input_channels)\n",
    "        self.ff_layer_norm = LayerNorm(features=input_channels)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        \n",
    "        enc_attention = self.multiattention_head_with_projections(Q_source=input_tensor,\n",
    "                                                                  V_source=input_tensor,\n",
    "                                                                  K_source=input_tensor) \n",
    "\n",
    "        attention_with_res = input_tensor.add(enc_attention)\n",
    "        \n",
    "        normed_attention_with_res = self.attention_layer_norm(attention_with_res)\n",
    "\n",
    "        _ = self.ff(normed_attention_with_res)\n",
    "        ff_with_res = _.add(normed_attention_with_res)\n",
    "        \n",
    "        normed_ff_with_res = self.ff_layer_norm(ff_with_res)\n",
    "        \n",
    "        return normed_ff_with_res\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 ff_projection_dim_x8=None,\n",
    "                 multi_x8=1,\n",
    "                 keys_queries_projection_dim_x8=1,\n",
    "                 values_projection_dim_x8=1):\n",
    "        super().__init__()\n",
    "        self.ff = FeedForward(input_channels = input_channels,\n",
    "                              ff_projection_dim_x8 = ff_projection_dim_x8)\n",
    "        \n",
    "        self.dec_multiattention_head_with_projections = Multiattention(qk_channels=input_channels,\n",
    "                                                                       v_channels=input_channels,\n",
    "                                                                       multi_x8=multi_x8,\n",
    "                                                                       keys_queries_projection_dim_x8=keys_queries_projection_dim_x8,\n",
    "                                                                       values_projection_dim_x8=values_projection_dim_x8)\n",
    "        \n",
    "        self.enc_multiattention_head_with_projections = Multiattention(qk_channels=input_channels,\n",
    "                                                                       v_channels=input_channels,\n",
    "                                                                       multi_x8=multi_x8,\n",
    "                                                                       keys_queries_projection_dim_x8=keys_queries_projection_dim_x8,\n",
    "                                                                       values_projection_dim_x8=values_projection_dim_x8)\n",
    "\n",
    "        self.dec_attention_layer_norm = LayerNorm(features=input_channels)\n",
    "        self.enc_attention_layer_norm = LayerNorm(features=input_channels)\n",
    "        self.ff_layer_norm = LayerNorm(features=input_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_tensor, encoder_output):\n",
    "        dec_attention = self.dec_multiattention_head_with_projections(Q_source=input_tensor,\n",
    "                                                                      K_source=input_tensor,\n",
    "                                                                      V_source=input_tensor) \n",
    "\n",
    "        dec_attention_with_res = input_tensor.add(dec_attention)\n",
    "        \n",
    "        normed_dec_attention_with_res = self.dec_attention_layer_norm(dec_attention_with_res)\n",
    "        \n",
    "        enc_attention = self.enc_multiattention_head_with_projections(Q_source=normed_dec_attention_with_res,\n",
    "                                                                      K_source=encoder_output,\n",
    "                                                                      V_source=encoder_output) \n",
    "        \n",
    "        enc_attention_with_res = normed_dec_attention_with_res.add(enc_attention)\n",
    "        \n",
    "        normed_enc_attention_with_res = self.enc_attention_layer_norm(enc_attention_with_res)\n",
    "\n",
    "        _ = self.ff(normed_enc_attention_with_res)\n",
    "        ff_with_res = _.add(normed_enc_attention_with_res)\n",
    "        \n",
    "        normed_ff_with_res = self.ff_layer_norm(ff_with_res)\n",
    "        \n",
    "        return normed_ff_with_res\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_channels, blocks=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_blocs = nn.ModuleList([EncoderBlock(input_channels=input_channels,\n",
    "                                                         ff_projection_dim_x8=256,\n",
    "                                                         multi_x8=1,\n",
    "                                                         keys_queries_projection_dim_x8=8,\n",
    "                                                         values_projection_dim_x8=8) for i in range(blocks)])\n",
    "        self.decoder_blocs = nn.ModuleList([DecoderBlock(input_channels=input_channels,\n",
    "                                                         ff_projection_dim_x8=256,\n",
    "                                                         multi_x8=1,\n",
    "                                                         keys_queries_projection_dim_x8=8,\n",
    "                                                         values_projection_dim_x8=8) for i in range(blocks)])\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        _,__ = input_tensor,input_tensor\n",
    "        \n",
    "        for i in range(len(self.encoder_blocs)):\n",
    "            _ = self.encoder_blocs[i](_)\n",
    "            __ = self.decoder_blocs[i](__,_)\n",
    "            \n",
    "        return _.add(__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 496 ms, total: 2.08 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand = np.random.randn(5, 1024, 512)\n",
    "\n",
    "net = Net(512, blocks=7)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    rand = Variable(torch.Tensor(rand)).cuda().half()\n",
    "    net.cuda().half()\n",
    "    \n",
    "    # these are automatically cuda\n",
    "    param_master_copy = [param.clone().type(torch.cuda.FloatTensor).detach() for param in net.parameters()]\n",
    "    for param in param_master_copy:\n",
    "        param.requires_grad = True\n",
    "    optimizer = torch.optim.SGD(param_master_copy, lr=.01,momentum=.0, \tweight_decay=.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    for i in range(20):\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        forward_pass = net(rand)\n",
    "        print(forward_pass.size())\n",
    "        loss = forward_pass.abs().mean(2).mean(1).mean(0)\n",
    "        loss.backward()\n",
    "\n",
    "        for param_master, param_w_grad in zip(param_master_copy, net.parameters()):\n",
    "            if param_master.grad is None:\n",
    "                param_master.grad = torch.nn.Parameter(param_master.data.new().resize_(*param_master.data.size()))\n",
    "            param_master.grad.data.copy_(param_w_grad.grad.data)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        params = list(net.parameters())\n",
    "        for i in range(len(params)):\n",
    "            params[i].data.copy_(param_master_copy[i].data)\n",
    "\n",
    "        ##learning_rate = 0.01\n",
    "        ##params = list(net.parameters())\n",
    "        ##for i in range(len(params)):\n",
    "        ##    param_master_copy[i].data.sub_(params[i].grad.data * learning_rate)\n",
    "        ##    params[i].data.copy_(param_master_copy[i].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "torch.Size([5, 1024, 512])\n",
      "CPU times: user 4.3 s, sys: 2.36 s, total: 6.66 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(param_master_copy,kde=False)\n",
    "#sns.distplot([param_master.grad.data for param_master in param_master_copy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "torch.Size([9, 1024, 512])\n",
      "CPU times: user 6.48 s, sys: 3.86 s, total: 10.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test()\n",
    "\n",
    "# device=titan5,runs=20,framework=pytorch,passes=both:\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP16: 4.5s\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP32: 6s\n",
    "#   input=(4, 1023, 511),net(511, blocks=7),FP16: 8s\n",
    "#   input=(4, 1023, 511),net(511, blocks=7),FP32: 8.5s\n",
    "#   input=(4, 1024, 512),net(512, blocks=7),FP16: 6s\n",
    "#   input=(4, 1024, 512),net(512, blocks=7),FP32: 8.4s - max batch_size\n",
    "#   input=(5, 1023, 511),net(511, blocks=7),FP16: 9s\n",
    "#   input=(5, 1023, 511),net(511, blocks=7),FP32: OOM\n",
    "#   input=(5, 1024, 512),net(512, blocks=7),FP16: 7s\n",
    "#   input=(5, 1024, 512),net(512, blocks=7),FP32: OOM\n",
    "#   input=(6, 1023, 511),net(511, blocks=7),FP16: 12s\n",
    "#   input=(6, 1024, 512),net(512, blocks=7),FP16: 9s\n",
    "#   input=(9, 1023, 511),net(511, blocks=7),FP16: 15.7s\n",
    "#   input=(9, 1024, 512),net(512, blocks=7),FP16: 11.5s - max batch_size\n",
    "# device=titan5,runs=20,framework=pytorch,passes=both,benchmark=True:\n",
    "#   input=(9, 1024, 512),net(512, blocks=7),FP16: 10s\n",
    "# device=980ti,runs=20,framework=pytorch,passes=both:\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP32: 10s - max batch_size\n",
    "# device=980ti,runs=20,framework=pytorch,passes=both,benchmark=True:\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP32: 9s\n",
    "# device=titan5,runs=20,framework=tf,passes=both:\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP16: 4.5s\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP32: 6s\n",
    "#   input=(4, 1023, 511),net(511, blocks=7),FP16: 10s\n",
    "#   input=(4, 1023, 511),net(511, blocks=7),FP32: 10s\n",
    "#   input=(4, 1024, 512),net(512, blocks=7),FP16: 6.5s\n",
    "#   input=(4, 1024, 512),net(512, blocks=7),FP32: 10s\n",
    "#   input=(5, 1023, 511),net(511, blocks=7),FP16: 11s\n",
    "#   input=(5, 1023, 511),net(511, blocks=7),FP32: 11.5s\n",
    "#   input=(5, 1024, 512),net(512, blocks=7),FP16: 7.5s\n",
    "#   input=(5, 1024, 512),net(512, blocks=7),FP32: 11.5s - max batch_size\n",
    "#   input=(6, 1023, 511),net(511, blocks=7),FP16: 13s\n",
    "#   input=(6, 1024, 512),net(512, blocks=7),FP16: 9s - max batch_size\n",
    "#   input=(9, 1024, 512),net(512, blocks=7),FP16: OOM\n",
    "#   input=(9, 1023, 511),net(511, blocks=7),FP16: OOM\n",
    "# device=980ti,runs=20,framework=tf,passes=both:\n",
    "#   input=(2, 1024, 512),net(512, blocks=7),FP32: 10s - max batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51444736\n"
     ]
    }
   ],
   "source": [
    "### net = Net(input_channels=512, blocks=7)\n",
    "model_parameters = list(filter(lambda p: p.requires_grad, net.parameters()))\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "#for p in model_parameters:\n",
    "#    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forward_pass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ace25ca857ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_master_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forward_pass' is not defined"
     ]
    }
   ],
   "source": [
    "del(rand)\n",
    "del(net)\n",
    "del(param_master_copy)\n",
    "del(optimizer)\n",
    "del(forward_pass)\n",
    "del(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
